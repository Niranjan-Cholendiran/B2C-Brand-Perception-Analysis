{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL Request Successful :)\n"
     ]
    }
   ],
   "source": [
    "# Define Company Website\n",
    "company_website= 'www.uber.com'\n",
    "\n",
    "# Verify TrustPilot website\n",
    "url= 'https://www.trustpilot.com/review/'+company_website\n",
    "page= requests.get(url) \n",
    "\n",
    "if(page.status_code == 200): \n",
    "    print(\"URL Request Successful :)\")\n",
    "else: \n",
    "    print(\"URL Request Failed :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML tags\n",
    "soup= bs(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Collect company details, review counts and number of pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Name: Uber\n",
      "Total number of reviews: 23919\n",
      "Average Star Rating: 3.0\n",
      "Company Website: www.uber.com\n",
      "Company Website in HTML: http://www.uber.com?utm_medium=company_profile&utm_source=trustpilot&utm_campaign=domain_click\n",
      "Total number of review pages to scrape: 811\n"
     ]
    }
   ],
   "source": [
    "# Company Name\n",
    "Company_name= soup.find_all(\"span\",class_=\"typography_display-s__qOjh6 typography_appearance-default__AAY17 title_displayName__TtDDM\")\n",
    "Company_name= Company_name[0].text.replace('\\xa0','')\n",
    "print('Company Name:',Company_name)\n",
    "\n",
    "# Total # Reviews\n",
    "total_reviews= soup.find_all(\"span\",class_=\"typography_body-l__KUYFJ typography_appearance-subtle__8_H2l styles_text__W4hWi\")\n",
    "total_reviews= int(total_reviews[0].text.split()[0].replace(',',''))\n",
    "print(\"Total number of reviews:\",total_reviews)\n",
    "\n",
    "# Average Star Rating\n",
    "avg_star_rating= soup.find_all(\"p\",class_=\"typography_body-l__KUYFJ typography_appearance-subtle__8_H2l\")\n",
    "avg_star_rating= float(avg_star_rating[0].text)\n",
    "print(\"Average Star Rating:\",avg_star_rating)\n",
    "\n",
    "# Company Website\n",
    "print(\"Company Website:\",company_website)\n",
    "\n",
    "\n",
    "# Company Website HTML\n",
    "    #test= soup.find_all(\"span\",class_=\"styles_prefix__a6Wee\")\n",
    "    #host_name= test[0].text\n",
    "    #test= soup.find_all(\"span\",class_=\"styles_suffix__2BIZf\")\n",
    "    #domain_name= test[0].text\n",
    "    #company_website= host_name + domain_name\n",
    "    #company_website\n",
    "test= soup.find_all(\"div\",class_=\"styles_cardBadge__LeaaQ\")\n",
    "company_website_html= test[0].find('a').get('href')\n",
    "print(\"Company Website in HTML:\",company_website_html)\n",
    "\n",
    "# Total Number of Pages\n",
    "span_pages= soup.find_all(\"span\",class_=\"typography_heading-xxs__QKBS8 typography_appearance-inherit__D7XqR typography_disableResponsiveSizing__OuNP7\")\n",
    "total_pages=[]\n",
    "for page in span_pages:\n",
    "    if(page.text.isnumeric()):\n",
    "        total_pages.append(int(page.text))\n",
    "total_pages = max(total_pages)\n",
    "print(\"Total number of review pages to scrape:\", total_pages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Scrape all reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the following contents from all pages:\n",
    "1. Reviewer Name \n",
    "2. Reviewer Total Reviews\n",
    "3. Location\n",
    "4. Review Star Rating\n",
    "5. Review Title\n",
    "6. Review\n",
    "7. Date\n",
    "8. Review Likes\n",
    "\n",
    "Remember to request websites in chunks, else the following error will occur:\n",
    "\n",
    "        \"We have received an unusually large amount of requests from your IP so you have been rate limited\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Script to pull data from pages that have even number of reviews\n",
    "\n",
    "* This code parses through each page and pulls all the review informations available\n",
    "* Page numbers with uneven review informations will be stored in the list uneven_record_pages, that'll be used later with an alternative data pull approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792  of 811\n",
      "793  of 811\n",
      "794  of 811\n",
      "Page 794 have uneven records\n",
      "795  of 811\n",
      "796  of 811\n",
      "Page 796 have uneven records\n",
      "797  of 811\n",
      "798  of 811\n",
      "Page 798 have uneven records\n",
      "799  of 811\n",
      "800  of 811\n",
      "801  of 811\n",
      "802  of 811\n",
      "803  of 811\n",
      "804  of 811\n",
      "805  of 811\n",
      "806  of 811\n",
      "807  of 811\n",
      "808  of 811\n",
      "809  of 811\n",
      "810  of 811\n",
      "811  of 811\n",
      "Page 811 have uneven records\n",
      "Failed page numbers: []\n",
      "Uneven # reviews page numbers: [4, 8, 10, 12, 19, 20, 22, 24, 25, 29, 30, 35, 36, 39, 40, 41, 44, 46, 47, 48, 49, 50, 51, 52, 53, 55, 62, 63, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 336, 340, 342, 343, 345, 346, 347, 348, 349, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 372, 375, 376, 377, 378, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 465, 466, 467, 468, 469, 470, 472, 473, 475, 476, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 504, 515, 516, 530, 532, 534, 535, 538, 539, 542, 549, 550, 551, 553, 555, 558, 559, 564, 570, 576, 577, 580, 583, 588, 589, 595, 599, 603, 606, 612, 614, 615, 616, 619, 624, 626, 629, 630, 631, 635, 640, 643, 646, 647, 649, 652, 653, 655, 656, 657, 658, 660, 661, 663, 664, 670, 671, 673, 674, 675, 678, 681, 686, 688, 694, 698, 700, 701, 702, 703, 707, 711, 712, 713, 716, 721, 722, 724, 728, 729, 733, 734, 736, 738, 739, 740, 741, 743, 746, 749, 750, 751, 761, 766, 768, 770, 774, 784, 785, 788, 794, 796, 798, 811]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_8816\\293267108.py:139: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df= existing_df.append(review_trust_pilot)\n"
     ]
    }
   ],
   "source": [
    "page_num_df=list()\n",
    "reviewer_name_df=list()\n",
    "reviewer_review_count_df=list()\n",
    "review_location_df=list()\n",
    "star_rating_df=list()\n",
    "review_title_df=list()\n",
    "reviews_df=list()\n",
    "review_month_df=list()\n",
    "review_day_df=list()\n",
    "review_year_df=list()\n",
    "\n",
    "failed_pages=[]\n",
    "uneven_record_pages = []\n",
    "#[4, 8, 10, 12, 19, 20, 22, 24, 25, 29, 30, 35, 36, 39, 40, 41, 44, 46, 47, 48, 49, 50, 51, 52, 53, 55, 62, 63, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 336, 340, 342, 343, 345, 346, 347, 348, 349, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 372, 375, 376, 377, 378, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 465, 466, 467, 468, 469, 470, 472, 473, 475, 476, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 504, 515, 516, 530, 532, 534, 535, 538, 539, 542, 549, 550, 551, 553, 555, 558, 559, 564, 570, 576, 577, 580, 583, 588, 589, 595, 599, 603, 606, 612, 614, 615, 616, 619, 624, 626, 629, 630, 631, 635, 640, 643, 646, 647, 649, 652, 653, 655, 656, 657, 658, 660, 661, 663, 664, 670, 671, 673, 674, 675, 678, 681, 686, 688, 694, 698, 700, 701, 702, 703, 707, 711, 712, 713, 716, 721, 722, 724, 728, 729, 733, 734, 736, 738, 739, 740, 741, 743, 746, 749, 750, 751, 761, 766, 768, 770, 774, 784, 785, 788, 794, 796, 798, 811]\n",
    "\n",
    "starting_page=1\n",
    "#total_pages= 2\n",
    "\n",
    "\n",
    "for page_number in range (starting_page,total_pages+1):\n",
    "    # Create URL\n",
    "    print(page_number,' of',total_pages)\n",
    "    page= '?page='+str(page_number)\n",
    "    page_url= 'https://www.trustpilot.com/review/'+company_website+page\n",
    "    page= requests.get(page_url) \n",
    "\n",
    "    \n",
    "    # Verify URL\n",
    "    if(page.status_code != 200): \n",
    "        print(\"Page\",page_number,\"URL Request Failed :( with error code:\", page.status_code)\n",
    "        failed_pages.append(page_number)\n",
    "        break\n",
    "\n",
    "    # Initate lists to store scrape results\n",
    "    page_num=list()\n",
    "    reviewer_name=list()\n",
    "    reviewer_review_count=list()\n",
    "    review_location=list()\n",
    "    star_rating=list()\n",
    "    review_title=list()\n",
    "    reviews=list()\n",
    "    review_month=list()\n",
    "    review_day=list()\n",
    "    review_year=list()\n",
    "    failed_pages=[]\n",
    "\n",
    "    # Parse the HTML tags\n",
    "    soup= bs(page.content, 'html.parser')\n",
    "\n",
    "    \n",
    "    # 1. Scrape Reviewer Name\n",
    "    span_reviewer_names= soup.find_all(\"span\",class_='typography_heading-xxs__QKBS8 typography_appearance-default__AAY17')\n",
    "    for name in span_reviewer_names:\n",
    "        reviewer_name.append(name.text)\n",
    "\n",
    "    # 2. Scrape Reviewer's Total Reviews\n",
    "    span_reviewer_review_count= soup.find_all(\"span\",class_='typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l')\n",
    "    for count in span_reviewer_review_count:\n",
    "        count= int(count.text.split()[0])\n",
    "        reviewer_review_count.append(count)\n",
    "\n",
    "    # 3. Scrape Review Location\n",
    "    div_review_location= soup.find_all(\"div\",class_='typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l styles_detailsIcon__Fo_ua')\n",
    "    for location in div_review_location:\n",
    "        review_location.append(location.text)\n",
    "\n",
    "    # 4. Scrape Review Star Rating\n",
    "    div_review_star_rating= soup.find_all(\"div\",class_='styles_reviewHeader__iU9Px')\n",
    "    for rating in div_review_star_rating:\n",
    "        star_rating.append(int(rating.get('data-service-review-rating')))\n",
    "\n",
    "    # 5. Scrape Review Title\n",
    "    h2_review_title= soup.find_all(\"h2\",class_='typography_heading-s__f7029 typography_appearance-default__AAY17')\n",
    "    for title in h2_review_title:\n",
    "        review_title.append(title.text)\n",
    "\n",
    "    # 6. Scrape Reviews\n",
    "    p_reviews= soup.find_all(\"p\",class_='typography_body-l__KUYFJ typography_appearance-default__AAY17 typography_color-black__5LYEn')\n",
    "    for review in p_reviews:\n",
    "        reviews.append(review.text)\n",
    "\n",
    "    # 7. Scrape Date\n",
    "    p_date= soup.find_all(\"p\",class_='typography_body-m__xgxZ_ typography_appearance-default__AAY17')\n",
    "    for date in p_date:\n",
    "        if(date.get('data-service-review-date-of-experience-typography')==\"true\"):\n",
    "            date= date.text\n",
    "            date= date.replace(\"Date of experience: \",\"\")\n",
    "            date= date.replace(\",\",\"\")\n",
    "            date= date.split(\" \")\n",
    "            review_month.append(date[0])\n",
    "            review_day.append(int(date[1]))\n",
    "            review_year.append(int(date[2]))   \n",
    "\n",
    "    # Check if the length of reviews are same. Do not store if not.\n",
    "    max_records= max([len(reviewer_name),len(reviewer_review_count),len(review_location),len(star_rating),len(review_title),len(reviews),len(review_month)])\n",
    "    if(len(reviewer_name) == max_records and len(reviewer_review_count) == max_records and len(review_location) == max_records and len(star_rating) == max_records and len(review_title) == max_records and len(reviews) == max_records and len(review_month) == max_records):\n",
    "        page_num_df+=[page_number]*max_records\n",
    "        reviewer_name_df+=reviewer_name\n",
    "        reviewer_review_count_df+=reviewer_review_count\n",
    "        review_location_df+=review_location\n",
    "        star_rating_df+=star_rating\n",
    "        review_title_df+=review_title\n",
    "        reviews_df+=reviews\n",
    "        review_month_df+=review_month\n",
    "        review_day_df+=review_day\n",
    "        review_year_df+=review_year\n",
    "    else:\n",
    "        print(\"Page\",page_number,\"have uneven records\")\n",
    "        uneven_record_pages.append(page_number)\n",
    "        continue\n",
    "\n",
    "print('Failed page numbers:', failed_pages)\n",
    "print('Uneven # reviews page numbers:', uneven_record_pages)\n",
    "review_trust_pilot=pd.DataFrame(\n",
    "    {\n",
    "    'review_page_number': page_num_df,\n",
    "    'reviewer_name':reviewer_name_df,\n",
    "    'reviewer_review_count':reviewer_review_count_df,\n",
    "    'review_location':review_location_df,\n",
    "    'star_rating': star_rating_df,\n",
    "    'review_title':review_title_df,\n",
    "    'review': reviews_df,\n",
    "    'review_month': review_month_df,\n",
    "    'review_dat': review_day_df,\n",
    "    'review_year': review_year_df\n",
    "    })\n",
    "\n",
    "review_trust_pilot['review_source']= 'Trustpilot'\n",
    "review_trust_pilot['company_name']= Company_name\n",
    "review_trust_pilot['company_website']= company_website\n",
    "review_trust_pilot['company_website_html']= company_website_html\n",
    "review_trust_pilot['total_reviews']= total_reviews\n",
    "review_trust_pilot['avg_star_rating']= avg_star_rating\n",
    "review_trust_pilot['total_review_pages']= total_pages\n",
    "\n",
    "review_trust_pilot\n",
    "\n",
    "# Merge new collected data to the existing dataframe\n",
    "existing_df= pd.read_csv(\"review_trustpilot_uber.csv\")\n",
    "merged_df= existing_df.append(review_trust_pilot)\n",
    "merged_df.to_csv(\"review_trustpilot_uber.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Script to pull data from page that have uneven number of reviews\n",
    "\n",
    "* This code parses by each container in each page and pulls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528\n"
     ]
    }
   ],
   "source": [
    "print(len(uneven_record_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed page numbers: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_8816\\1146341134.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df= existing_df.append(review_trust_pilot)\n"
     ]
    }
   ],
   "source": [
    "page_num_df= []\n",
    "failed_pages=[]\n",
    "reviewer_name_df=[]\n",
    "reviewer_review_count_df=[]\n",
    "review_location_df=[]\n",
    "star_rating_df=[]\n",
    "review_title_df=[]\n",
    "reviews_df=[]\n",
    "review_month_df=[]\n",
    "review_day_df=[]\n",
    "review_year_df=[]\n",
    "\n",
    "start_index=424\n",
    "\n",
    "for i in range(start_index,len(uneven_record_pages)+1):\n",
    "  print(i,' of',len(uneven_record_pages))\n",
    "  page_number= uneven_record_pages[i]\n",
    "  page= '?page='+str(page_number)\n",
    "  page_url= 'https://www.trustpilot.com/review/'+company_website+page\n",
    "  page= requests.get(page_url) \n",
    "\n",
    "  # Verify URL\n",
    "  if(page.status_code != 200): \n",
    "      print(\"Page\",page_number,\"URL Request Failed :( with error code:\", page.status_code)\n",
    "      print(\"Failed Record List Index:\", i)\n",
    "      failed_pages.append(page_number)\n",
    "      break\n",
    "  \n",
    "  # Parse the HTML tags\n",
    "  soup= bs(page.content, 'html.parser')\n",
    "  \n",
    "  # Get the containers list\n",
    "  containers= soup.find_all(\"div\",class_='styles_cardWrapper__LcCPA styles_show__HUXRb styles_reviewCard__9HxJJ')  \n",
    "\n",
    "  for container in containers:\n",
    "    page_num_df.append(page_number)\n",
    "\n",
    "    # Collect data from each container\n",
    "    span_reviewer_name= container.find(\"span\",class_='typography_heading-xxs__QKBS8 typography_appearance-default__AAY17')\n",
    "    span_reviewer_review_count= container.find(\"span\",class_='typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l')\n",
    "    div_review_location= container.find(\"div\",class_='typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l styles_detailsIcon__Fo_ua')\n",
    "    div_review_star_rating= container.find(\"div\",class_='styles_reviewHeader__iU9Px')\n",
    "    h2_review_title= container.find(\"h2\",class_='typography_heading-s__f7029 typography_appearance-default__AAY17')\n",
    "    p_review= container.find(\"p\",class_='typography_body-l__KUYFJ typography_appearance-default__AAY17 typography_color-black__5LYEn')\n",
    "    p_date= container.find(\"p\",class_='typography_body-m__xgxZ_ typography_appearance-default__AAY17')\n",
    "\n",
    "    # Append the data with values from previous containers. Append NA if data is not available in the website\n",
    "    if(type(span_reviewer_name)==type(None)): reviewer_name_df.append(None)\n",
    "    else: reviewer_name_df.append(span_reviewer_name.text)\n",
    "\n",
    "    if(type(span_reviewer_review_count)==type(None)): reviewer_review_count_df.append(None)\n",
    "    else: reviewer_review_count_df.append(int(span_reviewer_review_count.text.split()[0]))  \n",
    "\n",
    "    if(type(div_review_location)==type(None)): review_location_df.append(None)\n",
    "    else: review_location_df.append(div_review_location.text) \n",
    "\n",
    "    if(type(div_review_star_rating)==type(None)): star_rating_df.append(None)\n",
    "    else: star_rating_df.append(int(div_review_star_rating.get('data-service-review-rating')))\n",
    "\n",
    "    if(type(h2_review_title)==type(None)): review_title_df.append(None)\n",
    "    else: review_title_df.append(h2_review_title.text)\n",
    "\n",
    "    if(type(p_review)==type(None)): reviews_df.append(None)\n",
    "    else: reviews_df.append(p_review.text)\n",
    "\n",
    "    if(type(p_date)==type(None)): \n",
    "      review_month_df.append(None)\n",
    "      review_day_df.append(None)\n",
    "      review_year_df.append(None)\n",
    "    else: \n",
    "      date= p_date.text\n",
    "      date= date.replace(\"Date of experience: \",\"\")\n",
    "      date= date.replace(\",\",\"\")\n",
    "      date= date.split(\" \")\n",
    "      review_month_df.append(date[0])\n",
    "      review_day_df.append(int(date[1]))\n",
    "      review_year_df.append(int(date[2]))\n",
    "\n",
    "\n",
    "print('Failed page numbers:', failed_pages)\n",
    "review_trust_pilot=pd.DataFrame(\n",
    "    {\n",
    "    'review_page_number': page_num_df,\n",
    "    'reviewer_name':reviewer_name_df,\n",
    "    'reviewer_review_count':reviewer_review_count_df,\n",
    "    'review_location':review_location_df,\n",
    "    'star_rating': star_rating_df,\n",
    "    'review_title':review_title_df,\n",
    "    'review': reviews_df,\n",
    "    'review_month': review_month_df,\n",
    "    'review_dat': review_day_df,\n",
    "    'review_year': review_year_df\n",
    "    })\n",
    "\n",
    "review_trust_pilot['review_source']= 'Trustpilot'\n",
    "review_trust_pilot['company_name']= Company_name\n",
    "review_trust_pilot['company_website']= company_website\n",
    "review_trust_pilot['company_website_html']= company_website_html\n",
    "review_trust_pilot['total_reviews']= total_reviews\n",
    "review_trust_pilot['avg_star_rating']= avg_star_rating\n",
    "review_trust_pilot['total_review_pages']= total_pages\n",
    "\n",
    "review_trust_pilot\n",
    "\n",
    "# Merge new collected data to the existing dataframe\n",
    "existing_df= pd.read_csv(\"review_trustpilot_uber.csv\")\n",
    "merged_df= existing_df.append(review_trust_pilot)\n",
    "merged_df.to_csv(\"review_trustpilot_uber.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification: All page numbers (excep the last one) have same number of reviews in the colelcted dataset\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
